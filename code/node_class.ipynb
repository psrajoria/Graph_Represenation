{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Node2Vec:\n",
    "#     def __init__(self, graph):\n",
    "#         self.graph = graph\n",
    "#         self.alias_nodes = {}\n",
    "#         self.alias_edges = {}\n",
    "\n",
    "#     def preprocess_transition_probs(self, p, q):\n",
    "#         for node in self.graph:\n",
    "#             unnormalized_probs = [1.0 / len(self.graph[node][neighbor]) for neighbor in self.graph[node]]\n",
    "#             norm_constant = sum(unnormalized_probs)\n",
    "#             self.alias_nodes[node] = self.setup_alias_table(unnormalized_probs, norm_constant)\n",
    "\n",
    "#         for edge in self.graph.edges():\n",
    "#             self.alias_edges[edge] = self.get_alias_edge(edge[0], edge[1], p, q)\n",
    "\n",
    "#     def setup_alias_table(self, probs, norm_constant):\n",
    "#         num_nodes = len(probs)\n",
    "#         alias_table = np.zeros(num_nodes, dtype=np.int32)\n",
    "#         prob_table = np.zeros(num_nodes)\n",
    "\n",
    "#         smaller = []\n",
    "#         larger = []\n",
    "#         for i, prob in enumerate(probs):\n",
    "#             if prob > norm_constant:\n",
    "#                 larger.append(i)\n",
    "#             else:\n",
    "#                 smaller.append(i)\n",
    "\n",
    "#         while smaller and larger:\n",
    "#             small_idx = smaller.pop()\n",
    "#             large_idx = larger.pop()\n",
    "\n",
    "#             prob_table[small_idx] = probs[small_idx] * num_nodes\n",
    "#             alias_table[small_idx] = large_idx\n",
    "\n",
    "#             probs[large_idx] = (probs[large_idx] + probs[small_idx]) - norm_constant\n",
    "#             if probs[large_idx] > norm_constant:\n",
    "#                 larger.append(large_idx)\n",
    "#             else:\n",
    "#                 smaller.append(large_idx)\n",
    "\n",
    "#         for idx in smaller:\n",
    "#             prob_table[idx] = norm_constant\n",
    "#         for idx in larger:\n",
    "#             prob_table[idx] = norm_constant\n",
    "\n",
    "#         return alias_table, prob_table\n",
    "\n",
    "#     def get_alias_edge(self, src, dst, p, q):\n",
    "#         unnormalized_probs = []\n",
    "#         for neighbor in self.graph[dst]:\n",
    "#             if neighbor == src:\n",
    "#                 unnormalized_probs.append(self.graph[dst][neighbor]['weight'] / p)\n",
    "#             elif self.graph.has_edge(neighbor, src):\n",
    "#                 unnormalized_probs.append(self.graph[dst][neighbor]['weight'])\n",
    "#             else:\n",
    "#                 unnormalized_probs.append(self.graph[dst][neighbor]['weight'] / q)\n",
    "#         norm_constant = sum(unnormalized_probs)\n",
    "#         normalized_probs = [prob / norm_constant for prob in unnormalized_probs]\n",
    "#         return self.setup_alias_table(normalized_probs, 1.0)\n",
    "\n",
    "#     def simulate_walk(self, start_node, walk_length):\n",
    "#         walk = [start_node]\n",
    "#         while len(walk) < walk_length:\n",
    "#             current_node = walk[-1]\n",
    "#             neighbors = list(self.graph[current_node].keys())\n",
    "#             if len(neighbors) > 0:\n",
    "#                 next_node = self.draw_next_node(current_node, walk[-2] if len(walk) > 1 else None)\n",
    "#                 walk.append(next_node)\n",
    "#             else:\n",
    "#                 break\n",
    "#         return walk\n",
    "\n",
    "#     def draw_next_node(self, current_node, prev_node):\n",
    "#         if prev_node is None:\n",
    "#             alias_table, _ = self.alias_nodes[current_node]\n",
    "#         else:\n",
    "#             alias_table, _ = self.alias_edges[(prev_node, current_node)]\n",
    "#         return alias_table[random.randint(0, len(alias_table) - 1)]\n",
    "\n",
    "#     def generate_walks(self, num_walks, walk_length):\n",
    "#         walks = []\n",
    "#         nodes = list(self.graph.nodes())\n",
    "#         for _ in range(num_walks):\n",
    "#             random.shuffle(nodes)\n",
    "#             for node in nodes:\n",
    "#                 walk = self.simulate_walk(node, walk_length)\n",
    "#                 walks.append(walk)\n",
    "#         return walks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Node2Vec:\n",
    "#     def __init__(self):\n",
    "#         self.graph = {}\n",
    "#         self.alias_nodes = {}\n",
    "#         self.alias_edges = {}\n",
    "\n",
    "#     def read_graph(self, file_path):\n",
    "#         with open(file_path, 'r') as file:\n",
    "#             for line in file:\n",
    "#                 if line.startswith('#'):\n",
    "#                     continue\n",
    "#                 src, dst = map(int, line.strip().split())\n",
    "#                 if src not in self.graph:\n",
    "#                     self.graph[src] = {}\n",
    "#                 self.graph[src][dst] = {'weight': 1}\n",
    "\n",
    "#     def preprocess_transition_probs(self, p, q):\n",
    "#         for node in self.graph:\n",
    "#             unnormalized_probs = [1.0 / sum(edge['weight'] for edge in self.graph[node].values()) for _ in self.graph[node]]\n",
    "#             norm_constant = sum(unnormalized_probs)\n",
    "#             self.alias_nodes[node] = self.setup_alias_table(unnormalized_probs, norm_constant)\n",
    "\n",
    "#         for src in self.graph:\n",
    "#             for dst in self.graph[src]:\n",
    "#                 self.alias_edges[(src, dst)] = self.get_alias_edge(src, dst, p, q)\n",
    "\n",
    "#     def setup_alias_table(self, probs, norm_constant):\n",
    "#         num_nodes = len(probs)\n",
    "#         alias_table = np.zeros(num_nodes, dtype=np.int32)\n",
    "#         prob_table = np.zeros(num_nodes)\n",
    "\n",
    "#         smaller = []\n",
    "#         larger = []\n",
    "#         for i, prob in enumerate(probs):\n",
    "#             if prob > norm_constant:\n",
    "#                 larger.append(i)\n",
    "#             else:\n",
    "#                 smaller.append(i)\n",
    "\n",
    "#         while smaller and larger:\n",
    "#             small_idx = smaller.pop()\n",
    "#             large_idx = larger.pop()\n",
    "\n",
    "#             prob_table[small_idx] = probs[small_idx] * num_nodes\n",
    "#             alias_table[small_idx] = large_idx\n",
    "\n",
    "#             probs[large_idx] = (probs[large_idx] + probs[small_idx]) - norm_constant\n",
    "#             if probs[large_idx] > norm_constant:\n",
    "#                 larger.append(large_idx)\n",
    "#             else:\n",
    "#                 smaller.append(large_idx)\n",
    "\n",
    "#         for idx in smaller:\n",
    "#             prob_table[idx] = norm_constant\n",
    "#         for idx in larger:\n",
    "#             prob_table[idx] = norm_constant\n",
    "\n",
    "#         return alias_table, prob_table\n",
    "\n",
    "#     def get_alias_edge(self, src, dst, p, q):\n",
    "#         unnormalized_probs = []\n",
    "#         for neighbor in self.graph[dst]:\n",
    "#             if neighbor == src:\n",
    "#                 unnormalized_probs.append(self.graph[dst][neighbor]['weight'] / p)\n",
    "#             elif self.graph[neighbor].get(src):\n",
    "#                 unnormalized_probs.append(self.graph[dst][neighbor]['weight'])\n",
    "#             else:\n",
    "#                 unnormalized_probs.append(self.graph[dst][neighbor]['weight'] / q)\n",
    "#         norm_constant = sum(unnormalized_probs)\n",
    "#         normalized_probs = [prob / norm_constant for prob in unnormalized_probs]\n",
    "#         return self.setup_alias_table(normalized_probs, 1.0)\n",
    "\n",
    "#     def simulate_walk(self, start_node, walk_length):\n",
    "#         walk = [start_node]\n",
    "#         while len(walk) < walk_length:\n",
    "#             current_node = walk[-1]\n",
    "#             neighbors = list(self.graph[current_node].keys())\n",
    "#             if neighbors:\n",
    "#                 next_node = self.draw_next_node(current_node, walk[-2] if len(walk) > 1 else None)\n",
    "#                 walk.append(next_node)\n",
    "#             else:\n",
    "#                 break\n",
    "#         return walk\n",
    "\n",
    "#     def draw_next_node(self, current_node, prev_node):\n",
    "#         if prev_node is None:\n",
    "#             alias_table, _ = self.alias_nodes[current_node]\n",
    "#         else:\n",
    "#             alias_table, _ = self.alias_edges[(prev_node, current_node)]\n",
    "#         return alias_table[random.randint(0, len(alias_table) - 1)]\n",
    "\n",
    "#     def generate_walks(self, num_walks, walk_length):\n",
    "#         walks = []\n",
    "#         nodes = list(self.graph.keys())\n",
    "#         for _ in range(num_walks):\n",
    "#             random.shuffle(nodes)\n",
    "#             for node in nodes:\n",
    "#                 walk = self.simulate_walk(node, walk_length)\n",
    "#                 walks.append(walk)\n",
    "#         return walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Node2Vec:\n",
    "#     def __init__(self):\n",
    "#         self.graph = {}  # Dictionary to store the graph data\n",
    "#         self.alias_nodes = {}  # Dictionary to store alias nodes data\n",
    "#         self.alias_edges = {}  # Dictionary to store alias edges data\n",
    "\n",
    "#     def read_graph(self, file_path):\n",
    "#         \"\"\"\n",
    "#         Read the graph data from the given file path.\n",
    "#         Assumes the file format: FromNodeId    ToNodeId\n",
    "#         \"\"\"\n",
    "#         with open(file_path, 'r') as file:\n",
    "#             for line in file:\n",
    "#                 if line.startswith('#'):\n",
    "#                     continue\n",
    "#                 src, dst = map(int, line.strip().split())\n",
    "#                 if src not in self.graph:\n",
    "#                     self.graph[src] = {}\n",
    "#                 self.graph[src][dst] = {'weight': 1}\n",
    "\n",
    "#     # def preprocess_transition_probs(self, p, q):\n",
    "#     #     \"\"\"\n",
    "#     #     Preprocess transition probabilities for random walks.\n",
    "#     #     \"\"\"\n",
    "#     #     for node in self.graph:\n",
    "#     #         unnormalized_probs = [1.0 / sum(edge['weight'] for edge in self.graph[node].values()) for _ in self.graph[node]]\n",
    "#     #         norm_constant = sum(unnormalized_probs)\n",
    "#     #         self.alias_nodes[node] = self.setup_alias_table(unnormalized_probs, norm_constant)\n",
    "\n",
    "#     #     for src in self.graph:\n",
    "#     #         for dst in self.graph[src]:\n",
    "#     #             self.alias_edges[(src, dst)] = self.get_alias_edge(src, dst, p, q)\n",
    "#     def preprocess_transition_probs(self, p, q):\n",
    "#         \"\"\"\n",
    "#         Preprocess transition probabilities for random walks.\n",
    "#         \"\"\"\n",
    "#         for node in self.graph:\n",
    "#             unnormalized_probs = [1.0 / sum(edge['weight'] for edge in self.graph[node].values()) for _ in self.graph[node]]\n",
    "#             norm_constant = sum(unnormalized_probs)\n",
    "#             self.alias_nodes[node] = self.setup_alias_table(unnormalized_probs, norm_constant)\n",
    "\n",
    "#         for src in self.graph:\n",
    "#             for dst in self.graph[src]:\n",
    "#                 self.alias_edges[(src, dst)] = self.get_alias_edge(src, dst, p, q)\n",
    "\n",
    "\n",
    "#     # Helper method to set up alias table for nodes\n",
    "#     def setup_alias_table(self, probs, norm_constant):\n",
    "#         num_nodes = len(probs)\n",
    "#         alias_table = np.zeros(num_nodes, dtype=np.int32)\n",
    "#         prob_table = np.zeros(num_nodes)\n",
    "\n",
    "#         smaller = []\n",
    "#         larger = []\n",
    "#         for i, prob in enumerate(probs):\n",
    "#             if prob > norm_constant:\n",
    "#                 larger.append(i)\n",
    "#             else:\n",
    "#                 smaller.append(i)\n",
    "\n",
    "#         while smaller and larger:\n",
    "#             small_idx = smaller.pop()\n",
    "#             large_idx = larger.pop()\n",
    "\n",
    "#             prob_table[small_idx] = probs[small_idx] * num_nodes\n",
    "#             alias_table[small_idx] = large_idx\n",
    "\n",
    "#             probs[large_idx] = (probs[large_idx] + probs[small_idx]) - norm_constant\n",
    "#             if probs[large_idx] > norm_constant:\n",
    "#                 larger.append(large_idx)\n",
    "#             else:\n",
    "#                 smaller.append(large_idx)\n",
    "\n",
    "#         for idx in smaller:\n",
    "#             prob_table[idx] = norm_constant\n",
    "#         for idx in larger:\n",
    "#             prob_table[idx] = norm_constant\n",
    "\n",
    "#         return alias_table, prob_table\n",
    "\n",
    "#     # Helper method to get alias edge setup lists\n",
    "#     def get_alias_edge(self, src, dst, p, q):\n",
    "#         unnormalized_probs = []\n",
    "#         for neighbor in self.graph[dst]:\n",
    "#             if neighbor == src:\n",
    "#                 unnormalized_probs.append(self.graph[dst][neighbor]['weight'] / p)\n",
    "#             elif self.graph[neighbor].get(src):\n",
    "#                 unnormalized_probs.append(self.graph[dst][neighbor]['weight'])\n",
    "#             else:\n",
    "#                 unnormalized_probs.append(self.graph[dst][neighbor]['weight'] / q)\n",
    "#         norm_constant = sum(unnormalized_probs)\n",
    "#         normalized_probs = [prob / norm_constant for prob in unnormalized_probs]\n",
    "#         return self.setup_alias_table(normalized_probs, 1.0)\n",
    "\n",
    "#     # Helper method to simulate a random walk\n",
    "#     def simulate_walk(self, start_node, walk_length):\n",
    "#         walk = [start_node]\n",
    "#         while len(walk) < walk_length:\n",
    "#             current_node = walk[-1]\n",
    "#             neighbors = list(self.graph[current_node].keys())\n",
    "#             if neighbors:\n",
    "#                 next_node = self.draw_next_node(current_node, walk[-2] if len(walk) > 1 else None)\n",
    "#                 walk.append(next_node)\n",
    "#             else:\n",
    "#                 break\n",
    "#         return walk\n",
    "\n",
    "#     # Helper method to draw the next node in a random walk\n",
    "#     def draw_next_node(self, current_node, prev_node):\n",
    "#         if prev_node is None:\n",
    "#             alias_table, _ = self.alias_nodes[current_node]\n",
    "#         else:\n",
    "#             alias_table, _ = self.alias_edges[(prev_node, current_node)]\n",
    "#         return alias_table[random.randint(0, len(alias_table) - 1)]\n",
    "\n",
    "#     def generate_walks(self, num_walks, walk_length):\n",
    "#         \"\"\"\n",
    "#         Generate random walks for the graph.\n",
    "#         \"\"\"\n",
    "#         walks = []\n",
    "#         nodes = list(self.graph.keys())\n",
    "#         for _ in range(num_walks):\n",
    "#             random.shuffle(nodes)\n",
    "#             for node in nodes:\n",
    "#                 walk = self.simulate_walk(node, walk_length)\n",
    "#                 walks.append(walk)\n",
    "#         return walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node2Vec:\n",
    "    def __init__(self):\n",
    "        self.graph = {}\n",
    "        self.alias_nodes = {}\n",
    "        self.alias_edges = {}\n",
    "\n",
    "    def read_graph(self, file_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Read the graph data from the given file path.\n",
    "        Assumes the file format: FromNodeId    ToNodeId\n",
    "        \"\"\"\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                if line.startswith('#'):\n",
    "                    continue\n",
    "                src, dst = map(int, line.strip().split())\n",
    "                self.graph.setdefault(src, {})[dst] = {'weight': 1}\n",
    "\n",
    "    def preprocess_transition_probs(self, p: float, q: float) -> None:\n",
    "        \"\"\"\n",
    "        Preprocess transition probabilities for random walks.\n",
    "        \"\"\"\n",
    "        for node in self.graph:\n",
    "            unnormalized_probs = [edge['weight'] for edge in self.graph[node].values()]\n",
    "            norm_constant = sum(unnormalized_probs)\n",
    "            normalized_probs = [prob / norm_constant for prob in unnormalized_probs]\n",
    "            self.alias_nodes[node] = self.setup_alias_table(normalized_probs)\n",
    "\n",
    "        for src in self.graph:\n",
    "            for dst in self.graph[src]:\n",
    "                self.alias_edges[(src, dst)] = self.get_alias_edge(src, dst, p, q)\n",
    "\n",
    "    @staticmethod\n",
    "    def setup_alias_table(probs: list) -> tuple:\n",
    "        \"\"\"\n",
    "        Helper method to set up alias table for nodes.\n",
    "        \"\"\"\n",
    "        num_nodes = len(probs)\n",
    "        alias_table = np.zeros(num_nodes, dtype=np.int32)\n",
    "        prob_table = np.zeros(num_nodes)\n",
    "\n",
    "        small_probs = [i for i, prob in enumerate(probs) if prob < 1.0]\n",
    "        large_probs = [i for i, prob in enumerate(probs) if prob >= 1.0]\n",
    "\n",
    "        while small_probs and large_probs:\n",
    "            small_idx, large_idx = small_probs.pop(), large_probs.pop()\n",
    "            prob_table[small_idx] = probs[small_idx] * num_nodes\n",
    "            alias_table[small_idx] = large_idx\n",
    "            probs[large_idx] = probs[large_idx] + probs[small_idx] - 1.0\n",
    "            if probs[large_idx] < 1.0:\n",
    "                small_probs.append(large_idx)\n",
    "            else:\n",
    "                large_probs.append(large_idx)\n",
    "\n",
    "        for idx in small_probs + large_probs:\n",
    "            prob_table[idx] = 1.0\n",
    "\n",
    "        return alias_table, prob_table\n",
    "\n",
    "    def get_alias_edge(self, src: int, dst: int, p: float, q: float) -> tuple:\n",
    "        \"\"\"\n",
    "        Helper method to get alias edge setup lists.\n",
    "        \"\"\"\n",
    "        unnormalized_probs = [\n",
    "            self.graph[dst][neighbor]['weight'] / p if neighbor == src\n",
    "            else self.graph[dst][neighbor]['weight'] if self.graph[neighbor].get(src)\n",
    "            else self.graph[dst][neighbor]['weight'] / q\n",
    "            for neighbor in self.graph[dst]\n",
    "        ]\n",
    "        norm_constant = sum(unnormalized_probs)\n",
    "        normalized_probs = [prob / norm_constant for prob in unnormalized_probs]\n",
    "        return self.setup_alias_table(normalized_probs)\n",
    "\n",
    "    def simulate_walk(self, start_node: int, walk_length: int) -> list:\n",
    "        \"\"\"\n",
    "        Helper method to simulate a random walk.\n",
    "        \"\"\"\n",
    "        walk = [start_node]\n",
    "        while len(walk) < walk_length:\n",
    "            current_node = walk[-1]\n",
    "            neighbors = list(self.graph[current_node].keys())\n",
    "            if neighbors:\n",
    "                next_node = self.draw_next_node(current_node, walk[-2] if len(walk) > 1 else None)\n",
    "                walk.append(next_node)\n",
    "            else:\n",
    "                break\n",
    "        return walk\n",
    "\n",
    "    def draw_next_node(self, current_node: int, prev_node: int) -> int:\n",
    "        \"\"\"\n",
    "        Helper method to draw the next node in a random walk.\n",
    "        \"\"\"\n",
    "        alias_table, _ = self.alias_nodes[current_node] if prev_node is None else self.alias_edges[(prev_node, current_node)]\n",
    "        return alias_table[random.randint(0, len(alias_table) - 1)]\n",
    "\n",
    "    def generate_walks(self, num_walks: int, walk_length: int) -> list:\n",
    "        \"\"\"\n",
    "        Generate random walks for the graph.\n",
    "        \"\"\"\n",
    "        walks = []\n",
    "        nodes = list(self.graph.keys())\n",
    "        for _ in range(num_walks):\n",
    "            random.shuffle(nodes)\n",
    "            for node in nodes:\n",
    "                walk = self.simulate_walk(node, walk_length)\n",
    "                walks.append(walk)\n",
    "        return walks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "graph_file = \"aa.txt\"\n",
    "node2vec = Node2Vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa.txt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec.read_graph(graph_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec.preprocess_transition_probs(p=1, q=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m walks \u001b[39m=\u001b[39m node2vec\u001b[39m.\u001b[39;49mgenerate_walks(num_walks\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, walk_length\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[6], line 105\u001b[0m, in \u001b[0;36mNode2Vec.generate_walks\u001b[1;34m(self, num_walks, walk_length)\u001b[0m\n\u001b[0;32m    103\u001b[0m     random\u001b[39m.\u001b[39mshuffle(nodes)\n\u001b[0;32m    104\u001b[0m     \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m nodes:\n\u001b[1;32m--> 105\u001b[0m         walk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msimulate_walk(node, walk_length)\n\u001b[0;32m    106\u001b[0m         walks\u001b[39m.\u001b[39mappend(walk)\n\u001b[0;32m    107\u001b[0m \u001b[39mreturn\u001b[39;00m walks\n",
      "Cell \u001b[1;32mIn[6], line 81\u001b[0m, in \u001b[0;36mNode2Vec.simulate_walk\u001b[1;34m(self, start_node, walk_length)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(walk) \u001b[39m<\u001b[39m walk_length:\n\u001b[0;32m     80\u001b[0m     current_node \u001b[39m=\u001b[39m walk[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m---> 81\u001b[0m     neighbors \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraph[current_node]\u001b[39m.\u001b[39mkeys())\n\u001b[0;32m     82\u001b[0m     \u001b[39mif\u001b[39;00m neighbors:\n\u001b[0;32m     83\u001b[0m         next_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdraw_next_node(current_node, walk[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(walk) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "walks = node2vec.generate_walks(num_walks=4, walk_length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .mat file\n",
    "# mat_file = 'Homo_sapiens.mat'\n",
    "mat_file = 'POS.mat'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat(mat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file Platform: posix, Created on: Wed Nov  4 23:51:23 2015',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'group': <4777x40 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 6770 stored elements in Compressed Sparse Column format>,\n",
       " 'network': <4777x4777 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 184812 stored elements in Compressed Sparse Column format>}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the adjacency matrix from 'network'\n",
    "adjacency_matrix = data['network']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a NetworkX graph from the adjacency matrix\n",
    "# G = nx.Graph(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the adjacency matrix to a NetworkX graph\n",
    "G = nx.from_scipy_sparse_array(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x1c83e180ee0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Draw the graph\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m8\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m pos \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39;49mspring_layout(G, seed\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)  \u001b[39m# Adjust layout algorithm as needed\u001b[39;00m\n\u001b[0;32m      4\u001b[0m nx\u001b[39m.\u001b[39mdraw(G, pos, with_labels\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, node_color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlightblue\u001b[39m\u001b[39m'\u001b[39m, font_weight\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbold\u001b[39m\u001b[39m'\u001b[39m, node_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\psraj\\miniconda3\\envs\\torch\\lib\\site-packages\\networkx\\utils\\decorators.py:845\u001b[0m, in \u001b[0;36margmap.__call__.<locals>.func\u001b[1;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc\u001b[39m(\u001b[39m*\u001b[39margs, __wrapper\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 845\u001b[0m     \u001b[39mreturn\u001b[39;00m argmap\u001b[39m.\u001b[39m_lazy_compile(__wrapper)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m<class 'networkx.utils.decorators.argmap'> compilation 8:4\u001b[0m, in \u001b[0;36margmap_spring_layout_5\u001b[1;34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcollections\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgzip\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39minspect\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mitertools\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\psraj\\miniconda3\\envs\\torch\\lib\\site-packages\\networkx\\drawing\\layout.py:481\u001b[0m, in \u001b[0;36mspring_layout\u001b[1;34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[0m\n\u001b[0;32m    479\u001b[0m         nnodes, _ \u001b[39m=\u001b[39m A\u001b[39m.\u001b[39mshape\n\u001b[0;32m    480\u001b[0m         k \u001b[39m=\u001b[39m dom_size \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msqrt(nnodes)\n\u001b[1;32m--> 481\u001b[0m     pos \u001b[39m=\u001b[39m _sparse_fruchterman_reingold(\n\u001b[0;32m    482\u001b[0m         A, k, pos_arr, fixed, iterations, threshold, dim, seed\n\u001b[0;32m    483\u001b[0m     )\n\u001b[0;32m    484\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m    485\u001b[0m     A \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39mto_numpy_array(G, weight\u001b[39m=\u001b[39mweight)\n",
      "File \u001b[1;32mc:\\Users\\psraj\\miniconda3\\envs\\torch\\lib\\site-packages\\networkx\\utils\\decorators.py:845\u001b[0m, in \u001b[0;36margmap.__call__.<locals>.func\u001b[1;34m(_argmap__wrapper, *args, **kwargs)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc\u001b[39m(\u001b[39m*\u001b[39margs, __wrapper\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 845\u001b[0m     \u001b[39mreturn\u001b[39;00m argmap\u001b[39m.\u001b[39m_lazy_compile(__wrapper)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m<class 'networkx.utils.decorators.argmap'> compilation 12:4\u001b[0m, in \u001b[0;36margmap__sparse_fruchterman_reingold_9\u001b[1;34m(A, k, pos, fixed, iterations, threshold, dim, seed)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcollections\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgzip\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39minspect\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mitertools\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\psraj\\miniconda3\\envs\\torch\\lib\\site-packages\\networkx\\drawing\\layout.py:624\u001b[0m, in \u001b[0;36m_sparse_fruchterman_reingold\u001b[1;34m(A, k, pos, fixed, iterations, threshold, dim, seed)\u001b[0m\n\u001b[0;32m    621\u001b[0m     Ai \u001b[39m=\u001b[39m A\u001b[39m.\u001b[39mgetrowview(i)\u001b[39m.\u001b[39mtoarray()  \u001b[39m# TODO: revisit w/ sparse 1D container\u001b[39;00m\n\u001b[0;32m    622\u001b[0m     \u001b[39m# displacement \"force\"\u001b[39;00m\n\u001b[0;32m    623\u001b[0m     displacement[:, i] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m--> 624\u001b[0m         delta \u001b[39m*\u001b[39;49m (k \u001b[39m*\u001b[39;49m k \u001b[39m/\u001b[39;49m distance\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m2\u001b[39;49m \u001b[39m-\u001b[39;49m Ai \u001b[39m*\u001b[39;49m distance \u001b[39m/\u001b[39;49m k)\n\u001b[0;32m    625\u001b[0m     )\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    626\u001b[0m \u001b[39m# update positions\u001b[39;00m\n\u001b[0;32m    627\u001b[0m length \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqrt((displacement\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw the graph\n",
    "plt.figure(figsize=(10, 8))\n",
    "pos = nx.spring_layout(G, seed=42)  # Adjust layout algorithm as needed\n",
    "nx.draw(G, pos, with_labels=False, node_color='lightblue', font_weight='bold', node_size=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 4777\n",
      "Number of edges: 92517\n"
     ]
    }
   ],
   "source": [
    "# Find the number of nodes and edges\n",
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "\n",
    "print(\"Number of nodes:\", num_nodes)\n",
    "print(\"Number of edges:\", num_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
