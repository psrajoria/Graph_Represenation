{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_graph_from_txt(file_path):\n",
    "#     nodes = set()\n",
    "#     edges = []\n",
    "    \n",
    "#     with open(file_path, 'r') as file:\n",
    "#         lines = file.readlines()\n",
    "        \n",
    "#         # Skip the header lines starting with '#'\n",
    "#         for line in lines:\n",
    "#             if not line.startswith('#'):\n",
    "#                 break\n",
    "        \n",
    "#         # Read the edges\n",
    "#         for line in lines:\n",
    "#             if not line.startswith('#'):\n",
    "#                 from_node, to_node = map(int, line.strip().split())\n",
    "#                 nodes.add(from_node)\n",
    "#                 nodes.add(to_node)\n",
    "#                 edges.append((from_node, to_node))\n",
    "    \n",
    "#     return nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes, edges = read_graph_from_txt('aa.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Number of Nodes:\", len(nodes))\n",
    "# print(\"Number of Edges:\", len(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Read the graph from a .txt file\n",
    "def read_graph_from_txt(file_path):\n",
    "    nodes = set()\n",
    "    edges = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "        # Read the edges\n",
    "        for line in lines:\n",
    "            if not line.startswith('#'):\n",
    "                from_node, to_node = map(int, line.strip().split())\n",
    "                nodes.add(from_node)\n",
    "                nodes.add(to_node)\n",
    "                edges.append((from_node, to_node))\n",
    "\n",
    "    return nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "# import random\n",
    "# import numpy as np\n",
    "# from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_sample_graph():\n",
    "#     num_nodes = 100\n",
    "#     avg_degree = 10\n",
    "#     rewiring_prob = 0.1\n",
    "#     G = nx.watts_strogatz_graph(num_nodes, avg_degree, rewiring_prob)\n",
    "    \n",
    "#     return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the graph and plot it\n",
    "# graph = load_sample_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform link prediction using Node2Vec embeddings\n",
    "def link_prediction(graph, embedding_dimension=64, walk_length=30, num_walks=200, window_size=10):\n",
    "    node2vec = Node2Vec(graph, dimensions=embedding_dimension, walk_length=walk_length, num_walks=num_walks, workers=4)\n",
    "    model = node2vec.fit(window=window_size, min_count=1, batch_words=4)\n",
    "\n",
    "    # Generate embeddings for all nodes\n",
    "    node_embeddings = {node: model.wv[node] for node in graph.nodes()}\n",
    "\n",
    "    # Perform link prediction\n",
    "    link_predictions = []\n",
    "    for edge in graph.edges():\n",
    "        source, target = edge\n",
    "        if source not in node_embeddings or target not in node_embeddings:\n",
    "            continue\n",
    "        source_embedding = node_embeddings[source]\n",
    "        target_embedding = node_embeddings[target]\n",
    "        similarity = np.dot(source_embedding, target_embedding) / (np.linalg.norm(source_embedding) * np.linalg.norm(target_embedding))\n",
    "        link_predictions.append((source, target, similarity))\n",
    "\n",
    "    return link_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_file_path = \"aa.txt\"  # Replace with the path to your .txt file\n",
    "nodes, edges = read_graph_from_txt(graph_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph\n",
    "graph = nx.Graph()\n",
    "graph.add_nodes_from(nodes)\n",
    "graph.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_predictions = link_prediction(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract true labels and predicted scores for both positive and negative examples\n",
    "true_labels = []\n",
    "predicted_scores = []\n",
    "for edge in graph.edges():\n",
    "    source, target = edge\n",
    "    true_labels.append(1)\n",
    "    predicted_scores.append(next((similarity for src, tgt, similarity in link_predictions if (src == source and tgt == target) or (src == target and tgt == source)), 0.0))\n",
    "\n",
    "# Generate negative examples\n",
    "num_negative_examples = len(true_labels)\n",
    "while len(true_labels) < 2 * num_negative_examples:\n",
    "    non_edge = np.random.choice(list(graph.nodes()), size=2, replace=False)\n",
    "    if not graph.has_edge(*non_edge):\n",
    "        true_labels.append(0)\n",
    "        predicted_scores.append(next((similarity for src, tgt, similarity in link_predictions if (src == non_edge[0] and tgt == non_edge[1]) or (src == non_edge[1] and tgt == non_edge[0])), 0.0))\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_scores = np.array(predicted_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate AUC score\n",
    "auc_score = roc_auc_score(true_labels, predicted_scores)\n",
    "print(f\"AUC Score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "from gensim.models import Word2Vec\n",
    "import networkx as nx\n",
    "import random\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Node2Vec:\n",
    "    def __init__(self, graph, p, q, num_walks, walk_length, dimensions):\n",
    "        self.graph = graph\n",
    "        self.p = p  # Return parameter\n",
    "        self.q = q  # In-out parameter\n",
    "        self.num_walks = num_walks\n",
    "        self.walk_length = walk_length\n",
    "        self.dimensions = dimensions\n",
    "        \n",
    "    def simulate_walks(self, node):\n",
    "        walks = []\n",
    "        for _ in range(self.num_walks):\n",
    "            walk = [node]\n",
    "            while len(walk) < self.walk_length:\n",
    "                current_node = walk[-1]\n",
    "                neighbors = list(self.graph.neighbors(current_node))\n",
    "                if len(neighbors) > 0:\n",
    "                    if len(walk) == 1:\n",
    "                        walk.append(random.choice(neighbors))\n",
    "                    else:\n",
    "                        prev_node = walk[-2]\n",
    "                        next_node = self.sample_next_node(current_node, prev_node)\n",
    "                        walk.append(next_node)\n",
    "                else:\n",
    "                    break\n",
    "            walks.append(walk)\n",
    "        return walks\n",
    "    \n",
    "    def sample_next_node(self, current_node, prev_node):\n",
    "        neighbors = list(self.graph.neighbors(current_node))\n",
    "        weights = [1.0 if n == prev_node else 1.0/self.q if n in self.graph.neighbors(prev_node) else 1.0/self.p for n in neighbors]\n",
    "        return random.choices(neighbors, weights=weights)[0]\n",
    "    \n",
    "    # def learn_embeddings(self, walks):\n",
    "    #     model = Word2Vec(walks, size=self.dimensions, window=5, min_count=0, sg=1, workers=4, iter=1)\n",
    "    #     return model\n",
    "    def learn_embeddings(self, walks):\n",
    "        model = Word2Vec(walks, vector_size=self.dimensions, window=5, min_count=0, sg=1, workers=4, epochs=1)\n",
    "        return model\n",
    "    \n",
    "    def run(self):\n",
    "        walks = []\n",
    "        nodes = list(self.graph.nodes())\n",
    "        for node in nodes:\n",
    "            walks.extend(self.simulate_walks(node))\n",
    "        \n",
    "        model = self.learn_embeddings(walks)\n",
    "        return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph\n",
    "G = nx.karate_club_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of nodes and edges\n",
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of nodes and edges\n",
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "print(\"Number of nodes:\", num_nodes)\n",
    "print(\"Number of edges:\", num_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Visualize the original graph\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=500, ax=ax)\n",
    "ax.set_title(\"Original Graph\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize node2vec with parameters\n",
    "p = 1.0\n",
    "q = 1.0\n",
    "num_walks = 10\n",
    "walk_length = 4\n",
    "dimensions = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec = Node2Vec(G, p, q, num_walks, walk_length, dimensions)\n",
    "model = node2vec.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get node embeddings\n",
    "node_embeddings = {str(node): model.wv[str(node)] for node in G.nodes()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Embedding for node\", 2, \":\", embedding[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Embedding for node\", 7, \":\", embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample graph (you can replace this with your own graph)\n",
    "G = nx.karate_club_graph()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Visualize the original graph\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=500, ax=ax)\n",
    "ax.set_title(\"Original Graph\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute probabilities and generate walks\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=30, num_walks=200, p=0.5, q=2, workers=4)\n",
    "\n",
    "# Embed nodes\n",
    "model = node2vec.fit(window=10, min_count=1)\n",
    "\n",
    "# Get node embeddings\n",
    "node_embeddings = {str(node): model.wv[str(node)] for node in G.nodes()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the embeddings using scatter plot\n",
    "plt.figure(figsize=(20, 15))\n",
    "for node, embedding in node_embeddings.items():\n",
    "    plt.scatter(embedding[0], embedding[1], color='blue')\n",
    "    plt.annotate(node, (embedding[0], embedding[1]), alpha=0.5)\n",
    "plt.title(\"Node2Vec Embeddings\")\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import networkx as nx\n",
    "# from gensim.models import Word2Vec\n",
    "# from typing import List, Dict\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.manifold import TSNE\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# class AdvancedNode2Vec:\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         graph: nx.Graph,\n",
    "#         p: float,\n",
    "#         q: float,\n",
    "#         dimensions: int,\n",
    "#         num_walks: int,\n",
    "#         walk_length: int,\n",
    "#         window_size: int,\n",
    "#         num_epochs: int,\n",
    "#         workers: int\n",
    "#     ) -> None:\n",
    "#         self.graph = graph\n",
    "#         self.p = p\n",
    "#         self.q = q\n",
    "#         self.dimensions = dimensions\n",
    "#         self.num_walks = num_walks\n",
    "#         self.walk_length = walk_length\n",
    "#         self.window_size = window_size\n",
    "#         self.num_epochs = num_epochs\n",
    "#         self.workers = workers\n",
    "        \n",
    "#         self.walks = self.generate_walks()\n",
    "#         self.model = self.train_embedding()\n",
    "\n",
    "#     def generate_walks(self) -> List[List[str]]:\n",
    "#         walks = []\n",
    "#         for _ in range(self.num_walks):\n",
    "#             for node in self.graph.nodes():\n",
    "#                 walk = self.node2vec_walk(node)\n",
    "#                 walks.append(walk)\n",
    "#         return walks\n",
    "\n",
    "#     def node2vec_walk(self, start_node: str) -> List[str]:\n",
    "#         walk = [start_node]\n",
    "#         while len(walk) < self.walk_length:\n",
    "#             curr_node = walk[-1]\n",
    "#             neighbors = list(self.graph.neighbors(curr_node))\n",
    "#             if len(neighbors) > 0:\n",
    "#                 if len(walk) == 1:\n",
    "#                     walk.append(np.random.choice(neighbors))\n",
    "#                 else:\n",
    "#                     prev_node = walk[-2]\n",
    "#                     next_node = self.weighted_choice(neighbors, prev_node, curr_node)\n",
    "#                     walk.append(next_node)\n",
    "#             else:\n",
    "#                 break\n",
    "#         return walk\n",
    "\n",
    "#     def weighted_choice(self, neighbors: List[str], prev_node: str, curr_node: str) -> str:\n",
    "#         weights = []\n",
    "#         for neighbor in neighbors:\n",
    "#             if neighbor == prev_node:\n",
    "#                 weights.append(1 / self.p)\n",
    "#             elif self.graph.has_edge(curr_node, neighbor):\n",
    "#                 weights.append(1)\n",
    "#             else:\n",
    "#                 weights.append(1 / self.q)\n",
    "#         weights = np.array(weights)\n",
    "#         weights /= weights.sum()\n",
    "#         return np.random.choice(neighbors, p=weights)\n",
    "\n",
    "#     def embed_all_nodes(self) -> Dict[str, np.ndarray]:\n",
    "#         embeddings = {}\n",
    "#         for node in self.graph.nodes():\n",
    "#             embeddings[node] = self.model.wv[node]\n",
    "#         return embeddings\n",
    "\n",
    "#     def train_embedding(self) -> Word2Vec:\n",
    "#         model = Word2Vec(\n",
    "#             sentences=self.walks,\n",
    "#             vector_size=self.dimensions,\n",
    "#             window=self.window_size,\n",
    "#             sg=1,  # Skip-gram\n",
    "#             epochs=self.num_epochs,  \n",
    "#             workers=self.workers\n",
    "#         )\n",
    "#         return model\n",
    "    \n",
    "#     def get_node_similarity(self, node1: str, node2: str) -> float:\n",
    "#         return self.model.wv.similarity(node1, node2)\n",
    "    \n",
    "#     def get_node_clusters(self, num_clusters: int) -> Dict[int, List[str]]:\n",
    "#         node_embeddings = [self.model.wv[node] for node in self.graph.nodes()]\n",
    "#         kmeans = KMeans(n_clusters=num_clusters)\n",
    "#         cluster_assignments = kmeans.fit_predict(node_embeddings)\n",
    "\n",
    "#         clusters = {}\n",
    "#         for node, cluster_id in zip(self.graph.nodes(), cluster_assignments):\n",
    "#             if cluster_id not in clusters:\n",
    "#                 clusters[cluster_id] = []\n",
    "#             clusters[cluster_id].append(node)\n",
    "\n",
    "#         return clusters\n",
    "    \n",
    "#     def visualize_embeddings(self, nodes_to_visualize: List[str]) -> None:\n",
    "#         node_embeddings = [self.model.wv[node] for node in nodes_to_visualize]\n",
    "#         tsne = TSNE(n_components=2)\n",
    "#         embeddings_2d = tsne.fit_transform(node_embeddings)\n",
    "\n",
    "#         plt.figure(figsize=(10, 8))\n",
    "#         plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1])\n",
    "#         for i, label in enumerate(nodes_to_visualize):\n",
    "#             plt.annotate(label, (embeddings_2d[i, 0], embeddings_2d[i, 1]))\n",
    "#         plt.title(\"Node Embeddings Visualization\")\n",
    "#         plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node2Vec:\n",
    "    def __init__(self, graph, p, q, dimensions, num_walks, walk_length, window_size, num_epochs, workers):\n",
    "        self.graph = graph\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "        self.dimensions = dimensions\n",
    "        self.num_walks = num_walks\n",
    "        self.walk_length = walk_length\n",
    "        self.window_size = window_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.workers = workers\n",
    "        \n",
    "        self.walks = self.generate_walks()\n",
    "        self.model = self.train_embedding()\n",
    "\n",
    "    def generate_walks(self):\n",
    "        walks = []\n",
    "        for _ in range(self.num_walks):\n",
    "            for node in self.graph.nodes():\n",
    "                walk = self.node2vec_walk(node)\n",
    "                walks.append(walk)\n",
    "        return walks\n",
    "\n",
    "    def node2vec_walk(self, start_node):\n",
    "        walk = [start_node]\n",
    "        while len(walk) < self.walk_length:\n",
    "            curr_node = walk[-1]\n",
    "            neighbors = list(self.graph.neighbors(curr_node))\n",
    "            if len(neighbors) > 0:\n",
    "                if len(walk) == 1:\n",
    "                    walk.append(np.random.choice(neighbors))\n",
    "                else:\n",
    "                    prev_node = walk[-2]\n",
    "                    next_node = self.weighted_choice(neighbors, prev_node, curr_node)\n",
    "                    walk.append(next_node)\n",
    "            else:\n",
    "                break\n",
    "        return walk\n",
    "\n",
    "    def weighted_choice(self, neighbors, prev_node, curr_node):\n",
    "        weights = []\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor == prev_node:\n",
    "                weights.append(1/self.p)\n",
    "            elif self.graph.has_edge(curr_node, neighbor):\n",
    "                weights.append(1)\n",
    "            else:\n",
    "                weights.append(1/self.q)\n",
    "        weights = np.array(weights)\n",
    "        weights /= weights.sum()\n",
    "        return np.random.choice(neighbors, p=weights)\n",
    "\n",
    "    def embed_all_nodes(self):\n",
    "        embeddings = {}\n",
    "        for node in self.graph.nodes():\n",
    "            embeddings[node] = self.model.wv[node]\n",
    "        return embeddings\n",
    "\n",
    "    def train_embedding(self):\n",
    "        model = Word2Vec(\n",
    "            sentences=self.walks,\n",
    "            vector_size=self.dimensions,\n",
    "            window=self.window_size,\n",
    "            sg=1,  # Skip-gram\n",
    "            epochs=self.num_epochs,  \n",
    "            workers=self.workers\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a sample graph\n",
    "# G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G.add_edges_from([(1, 2), (1, 3), (2, 3), (3, 4), (4, 5), (4, 6), (5, 6),(6,1)])\n",
    "# G.add_edges_from([(1, 2), (1, 3), (1,4),(1,5), (2, 3), (3, 4), (4, 5), (4, 6), (5, 6),(6,1)])\n",
    "\n",
    "G.add_edges_from([(1,4),(1,2),(1,3),(1,5),(2,3),(4,6),(4,7),(4,8),(6,8)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random graph with 20 nodes and 40 edges\n",
    "# G = nx.erdos_renyi_graph(n=20, p=0.3)\n",
    "G = nx.karate_club_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of nodes and edges\n",
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "print(\"Number of nodes:\", num_nodes)\n",
    "print(\"Number of edges:\", num_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "import numpy as np\n",
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "# List of dimensions to iterate over\n",
    "dimension_list = [32, 64, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # List of dimensions to iterate over\n",
    "# dimension_list = [32, 64, 128]\n",
    "# # Iterate over different dimensions\n",
    "# for dimensions in dimension_list:\n",
    "#     # Set random seed for Node2Vec and NumPy within each iteration\n",
    "#     np.random.seed(seed_value)\n",
    "    \n",
    "#     # Create the Node2Vec model instance\n",
    "#     node2vec = Node2Vec(G, p=1, q=0.5, dimensions=dimensions, num_walks=10, walk_length=80, window_size=10, num_epochs=100, workers=4)\n",
    "    \n",
    "#     # Train the embedding model using your custom class's train_embedding() method\n",
    "#     model = node2vec.train_embedding()\n",
    "    \n",
    "#     # Embed all nodes\n",
    "#     node_embeddings = {node: model.wv[node] for node in G.nodes()}\n",
    "    \n",
    "#     # Create a new figure and axis\n",
    "#     fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "#     # Visualize the original graph\n",
    "#     pos = nx.spring_layout(G, seed=seed_value)\n",
    "#     nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=500, ax=ax)\n",
    "#     ax.set_title(\"Original Graph\")\n",
    "#     plt.show()\n",
    "    \n",
    "#     # Plot the embeddings with node numbers\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     for node, embedding in node_embeddings.items():\n",
    "#         plt.scatter(embedding[0], embedding[1], s=100)\n",
    "#         plt.text(embedding[0], embedding[1], str(node), fontsize=10, ha='center', va='center')\n",
    "#     plt.title(f\"Node2Vec Embeddings with Node Numbers (Dimensions={dimensions})\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the Node2Vec model\n",
    "# node2vec = Node2Vec(G, p=1, q=1, dimensions=128, num_walks=10, walk_length=80, window_size=10, num_iter=50, workers=4)\n",
    "node2vec = Node2Vec(G, p=1, q=0.5, dimensions=32, num_walks=4, walk_length=4, window_size=10, num_epochs=100, workers=4)\n",
    "node2vec_1 = Node2Vec(G, p=1, q=0.5, dimensions=64, num_walks=4, walk_length=4, window_size=10, num_epochs=100, workers=4)\n",
    "node2vec_2 = Node2Vec(G, p=1, q=0.5, dimensions=128, num_walks=4, walk_length=4, window_size=10, num_epochs=100, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(nrows=len(dimension_list), ncols=2, figsize=(15, 10))\n",
    "\n",
    "# Iterate over different dimensions\n",
    "for idx, dimensions in enumerate(dimension_list):\n",
    "    # Set random seed for Node2Vec and NumPy within each iteration\n",
    "    np.random.seed(seed_value)\n",
    "    \n",
    "    # Create the Node2Vec model instance\n",
    "    node2vec = Node2Vec(G, p=0.4, q=0.5, dimensions=dimensions, num_walks=10, walk_length=80, window_size=10, num_epochs=100, workers=4)\n",
    "    \n",
    "    # Train the embedding model using your custom class's train_embedding() method\n",
    "    model = node2vec.train_embedding()\n",
    "    \n",
    "    # Embed all nodes\n",
    "    node_embeddings = {node: model.wv[node] for node in G.nodes()}\n",
    "    \n",
    "    # Visualize the original graph\n",
    "    pos = nx.spring_layout(G, seed=seed_value)\n",
    "    ax = axes[idx, 0]\n",
    "    nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=500, ax=ax)\n",
    "    ax.set_title(f\"Original Graph (Dimensions={dimensions})\")\n",
    "    \n",
    "    # Plot the embeddings with node numbers\n",
    "    ax = axes[idx, 1]\n",
    "    for node, embedding in node_embeddings.items():\n",
    "        ax.scatter(embedding[0], embedding[1], s=100)\n",
    "        ax.text(embedding[0], embedding[1], str(node), fontsize=10, ha='center', va='center')\n",
    "    ax.set_title(f\"Node2Vec Embeddings (Dimensions={dimensions})\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dimensions and walk lengths to iterate over\n",
    "dimension_list = [32, 64, 128]\n",
    "walk_length_list = [10, 20, 40]\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(nrows=len(dimension_list) * len(walk_length_list), ncols=2, figsize=(25, 25))\n",
    "\n",
    "# Iterate over different dimensions\n",
    "for d_idx, dimensions in enumerate(dimension_list):\n",
    "    for w_idx, walk_length in enumerate(walk_length_list):\n",
    "        # Set random seed for Node2Vec and NumPy within each iteration\n",
    "        np.random.seed(seed_value)\n",
    "        \n",
    "        # Create the Node2Vec model instance\n",
    "        node2vec = Node2Vec(G, p=0.4, q=0.5, dimensions=dimensions, num_walks=10, walk_length=walk_length, window_size=10, num_epochs=100, workers=4)\n",
    "        \n",
    "        # Train the embedding model using your custom class's train_embedding() method\n",
    "        model = node2vec.train_embedding()\n",
    "        \n",
    "        # Embed all nodes\n",
    "        node_embeddings = {node: model.wv[node] for node in G.nodes()}\n",
    "        \n",
    "        # Visualize the original graph\n",
    "        pos = nx.spring_layout(G, seed=seed_value)\n",
    "        ax = axes[d_idx * len(walk_length_list) + w_idx, 0]\n",
    "        nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=500, ax=ax)\n",
    "        ax.set_title(f\"Original Graph (Dimensions={dimensions}, Walk Length={walk_length})\")\n",
    "        \n",
    "        # Plot the embeddings with node numbers\n",
    "        ax = axes[d_idx * len(walk_length_list) + w_idx, 1]\n",
    "        for node, embedding in node_embeddings.items():\n",
    "            ax.scatter(embedding[0], embedding[1], s=100)\n",
    "            ax.text(embedding[0], embedding[1], str(node), fontsize=10, ha='center', va='center')\n",
    "        ax.set_title(f\"Node2Vec Embeddings (Dimensions={dimensions}, Walk Length={walk_length})\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embeddings for a specific node\n",
    "node_embedding = node2vec.model.wv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dictionary and count elements in each array\n",
    "array_lengths = {}\n",
    "for key, value in node_embeddings.items():\n",
    "    array_lengths[key] = len(value)\n",
    "\n",
    "# Print the counts\n",
    "for key, length in array_lengths.items():\n",
    "    print(f\"Length of {key}: {length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed all nodes\n",
    "node_embeddings = node2vec.embed_all_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(node_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Visualize the original graph\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=500, ax=ax)\n",
    "ax.set_title(\"Original Graph\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After embeddings\n",
    "plt.figure(figsize=(12, 6))\n",
    "for node, embedding in node_embeddings.items():\n",
    "    plt.scatter(embedding[0], embedding[1], label=node)\n",
    "plt.title(\"Node2Vec Embeddings\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the embeddings with node numbers\n",
    "plt.figure(figsize=(20, 15))\n",
    "for node, embedding in node_embeddings.items():\n",
    "    plt.scatter(embedding[0], embedding[1], s=100)\n",
    "    plt.text(embedding[0], embedding[1], str(node), fontsize=12, ha='center', va='center')\n",
    "plt.title(\"Node2Vec Embeddings with Node Numbers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarities between embeddings\n",
    "embeddings_array = np.array(list(node_embeddings.values()))\n",
    "cosine_similarities = cosine_similarity(embeddings_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cosine similarity heatmap\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(cosine_similarities, cmap='coolwarm', interpolation='nearest')\n",
    "plt.colorbar(label='Cosine Similarity')\n",
    "plt.title(\"Node2Vec Embeddings Cosine Similarity Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dimensions and walk lengths to iterate over\n",
    "dimension_list = [32, 64, 128]\n",
    "walk_length_list = [10, 20, 40]\n",
    "\n",
    "# Function to generate node features (replace this with your own feature generation logic)\n",
    "def generate_features(node):\n",
    "    # Example: return some numeric features for each node\n",
    "    return np.random.rand(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(nrows=len(dimension_list) * len(walk_length_list), ncols=2, figsize=(15, 15))\n",
    "\n",
    "# Iterate over different dimensions\n",
    "for d_idx, dimensions in enumerate(dimension_list):\n",
    "    for w_idx, walk_length in enumerate(walk_length_list):\n",
    "        # Set random seed for Node2Vec and NumPy within each iteration\n",
    "        np.random.seed(seed_value)\n",
    "        \n",
    "        # Create the Node2Vec model instance\n",
    "        node2vec = Node2Vec(G, p=0.4, q=0.5, dimensions=dimensions, num_walks=10, walk_length=walk_length, window_size=10, num_epochs=100, workers=4)\n",
    "        \n",
    "        # Train the embedding model using your custom class's train_embedding() method\n",
    "        model = node2vec.train_embedding()\n",
    "        \n",
    "        # Generate node features\n",
    "        node_features = {node: generate_features(node) for node in G.nodes()}\n",
    "        \n",
    "        # Split the graph into training and testing sets\n",
    "        train_nodes, test_nodes = train_test_split(list(G.nodes()), test_size=0.2, random_state=seed_value)\n",
    "        \n",
    "        # Create balanced dataset\n",
    "        neighbors_exist = [node for node in train_nodes if len(list(G.neighbors(node))) > 0]\n",
    "        neighbors_not_exist = [node for node in train_nodes if len(list(G.neighbors(node))) == 0]\n",
    "        \n",
    "        # Check if there are nodes with neighbors\n",
    "        if len(neighbors_exist) > 0:\n",
    "            # Randomly sample from neighbors_exist to balance the dataset\n",
    "            sampled_neighbors_exist = np.random.choice(neighbors_exist, size=len(neighbors_not_exist), replace=True)\n",
    "            \n",
    "            # Combine the balanced samples\n",
    "            balanced_train_nodes = np.concatenate([sampled_neighbors_exist, neighbors_not_exist])\n",
    "            \n",
    "            # Generate labels for the balanced dataset\n",
    "            y_train = np.array([1 if node in neighbors_exist else 0 for node in balanced_train_nodes])\n",
    "            \n",
    "            # Prepare training data\n",
    "            X_train = np.array([model.wv[node] for node in balanced_train_nodes])\n",
    "\n",
    "            # Check if X_train is not empty\n",
    "            if len(X_train) > 0:\n",
    "                # Train a classifier (Random Forest)\n",
    "                classifier = RandomForestClassifier(random_state=seed_value)\n",
    "                classifier.fit(X_train, y_train)\n",
    "                \n",
    "                # Prepare testing data\n",
    "                X_test = np.array([model.wv[node] for node in test_nodes])\n",
    "                y_test = np.array([1 if node in G.neighbors(node) else 0 for node in test_nodes])\n",
    "                \n",
    "                # Evaluate the classifier's performance\n",
    "                y_pred = classifier.predict(X_test)\n",
    "                report = classification_report(y_test, y_pred)\n",
    "                print(f\"Classification Report for Dimensions={dimensions}, Walk Length={walk_length}:\\n{report}\")\n",
    "                \n",
    "                # Visualize the original graph\n",
    "                pos = nx.spring_layout(G, seed=seed_value)\n",
    "                ax = axes[d_idx * len(walk_length_list) + w_idx, 0]\n",
    "                nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=500, ax=ax)\n",
    "                ax.set_title(f\"Original Graph (Dimensions={dimensions}, Walk Length={walk_length})\")\n",
    "                \n",
    "                # Plot the embeddings with node numbers\n",
    "                ax = axes[d_idx * len(walk_length_list) + w_idx, 1]\n",
    "                for node, embedding in node_embeddings.items():\n",
    "                    ax.scatter(embedding[0], embedding[1], s=100)\n",
    "                    ax.text(embedding[0], embedding[1], str(node), fontsize=10, ha='center', va='center')\n",
    "                ax.set_title(f\"Node2Vec Embeddings (Dimensions={dimensions}, Walk Length={walk_length})\")\n",
    "            else:\n",
    "                print(\"No embeddings for nodes in the training dataset.\")\n",
    "        else:\n",
    "            print(\"No nodes with neighbors in the training dataset.\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import os\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from stellargraph.data import BiasedRandomWalk\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph import datasets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "\n",
    "print(\"Number of nodes:\", num_nodes)\n",
    "print(\"Number of edges:\", num_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the NetworkX graph to a StellarGraph object\n",
    "stellar_graph = StellarGraph.from_networkx(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stellar_graph.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = BiasedRandomWalk(stellar_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walks = rw.run(\n",
    "    nodes=list(stellar_graph.nodes()),  # root nodes\n",
    "    length=100,  # maximum length of a random walk\n",
    "    n=10,  # number of random walks per root node\n",
    "    p=0.5,  # Defines (unormalised) probability, 1/p, of returning to source node\n",
    "    q=2.0,  # Defines (unormalised) probability, 1/q, for moving away from source node\n",
    ")\n",
    "print(\"Number of random walks: {}\".format(len(walks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "str_walks = [[str(n) for n in walk] for walk in walks]\n",
    "# model = Word2Vec(str_walks, size=128, window=5, min_count=0, sg=1, workers=2, iter=1)\n",
    "model = Word2Vec(sentences=str_walks, vector_size=128, window=5, min_count=0, workers=4,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv[\"1\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve node embeddings and corresponding subjects\n",
    "node_ids = model.wv.index_to_key  # list of node IDs\n",
    "node_embeddings = (\n",
    "    model.wv.vectors\n",
    ")  # numpy.ndarray of size number of nodes times embeddings dimensionality\n",
    "# node_targets = node_subjects[[int(node_id) for node_id in node_ids]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = datasets.Cora()\n",
    "# display(HTML(dataset.description))\n",
    "# G_1, node_subjects = dataset.load(largest_connected_component_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply t-SNE transformation on node embeddings\n",
    "tsne = TSNE(n_components=2)\n",
    "node_embeddings_2d = tsne.fit_transform(node_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use KMeans to cluster nodes into subjects\n",
    "num_clusters = 5  # Number of clusters (subjects)\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "node_targets = kmeans.fit_predict(node_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the points\n",
    "alpha = 0.7\n",
    "label_map = {l: i for i, l in enumerate(np.unique(node_targets))}\n",
    "node_colours = [label_map[target] for target in node_targets]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(\n",
    "    node_embeddings_2d[:, 0],\n",
    "    node_embeddings_2d[:, 1],\n",
    "    c=node_colours,\n",
    "    cmap=\"jet\",\n",
    "    alpha=alpha,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X will hold the 128-dimensional input features\n",
    "X = node_embeddings\n",
    "# y holds the corresponding target values\n",
    "y = np.array(node_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Array shapes:\\n X_train = {}\\n y_train = {}\\n X_test = {}\\n y_test = {}\".format(\n",
    "        X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegressionCV(\n",
    "    Cs=5, cv=5, scoring=\"accuracy\", verbose=True, multi_class=\"ovr\", max_iter=300\n",
    ")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
